from dotenv import load_dotenv
import os
import re
import json
import html
from openai import OpenAI
import requests
from fastapi import Request, FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
import cohere
from fastapi import Body
from fastapi import Request
from fastapi import FastAPI, UploadFile, File
from fastapi.responses import JSONResponse
from google.cloud import vision
from fastapi.responses import PlainTextResponse
from fastapi.middleware.cors import CORSMiddleware
from PyPDF2 import PdfReader
import tempfile
from google.oauth2 import service_account
from google.cloud import translate_v2 as google_translate
from google.cloud import vision
import html
import time
import io, os, re, zipfile, tempfile, pathlib, subprocess
import xml.etree.ElementTree as ET
import speech_recognition as sr  # ìŒì„±ì¸ì‹
from pydub import AudioSegment
from io import BytesIO
import imageio_ffmpeg
from hanspell import spell_checker
from typing import Optional, Tuple, List
from PIL import Image

# PDF/ì˜¤í”¼ìŠ¤ íŒŒì„œ
import fitz, base64                     
from docx import Document       
from pptx import Presentation   
from openpyxl import load_workbook
import olefile                  
import chardet      
from docx import Document
from pptx import Presentation


try:
    import kss
    HAS_KSS = True
except Exception:
    HAS_KSS = False

_KO_TERMINALS = ("ë‹¤.", "ìš”.", "ì…ë‹ˆë‹¤.", "ì¸ê°€ìš”?", "ì¼ê¹Œìš”?",
                 "ìŠµë‹ˆê¹Œ?", "í–ˆë‹¤.", "í–ˆë‹¤ê³ ", "í–ˆë‹¤ë©°")

def split_ko_sentences(text: str):
    text = (text or "").strip()
    if not text:
        return []
    if HAS_KSS:
        # kssëŠ” ì¤„ë°”ê¿ˆ í¬í•¨í•´ë„ ì˜ ìª¼ê°œì¤Œ
        return [s.strip() for s in kss.split_sentences(text) if s.strip()]
    # fallback: ì•„ì£¼ ë‹¨ìˆœí•œ ê·œì¹™
    #  - ì¤„ë°”ê¿ˆì„ ê³µë°±ìœ¼ë¡œ ë°”ê¾¸ê³ 
    #  - ë¬¸ì¥ë§(ë‹¤./ìš”./ì…ë‹ˆë‹¤./?! ë“±) ê¸°ì¤€ ëŒ€ëµ ë¶„ë¦¬
    t = re.sub(r"[ \t]*\n[ \t]*", " ", text)
    parts = re.split(r"(?<=[\.!?]|ë‹¤\.|ìš”\.|ì…ë‹ˆë‹¤\.)\s+", t)
    return [p.strip() for p in parts if p.strip()]

def count_ko_sentences(text: str) -> int:
    return len(split_ko_sentences(text))

def _expand_clamp(v, lo, hi):
    try:
        v = int(v)
    except Exception:
        v = lo
    return max(lo, min(v, hi))

def _expand_split_sentences_kor(text: str):
    """í•œê¸€ ë¬¸ì¥ ê²½ê³„ ëŒ€ì¶© ì˜ë¼ë‚´ëŠ” ê²½ëŸ‰ ë¶„ë¦¬ê¸°(ë§ˆì¹¨í‘œ/ìš”/ë‹ˆë‹¤/â€¦ ê¸°ì¤€)."""
    t = re.sub(r'\s*\n+\s*', '\n', (text or '').strip())
    s = re.sub(r'([\.!?â€¦])\s+', r'\1\n', t)
    s = re.sub(r'(ë‹¤\.|ìš”\.|ë‹ˆë‹¤\.)\s+', r'\1\n', s)
    parts = [p.strip() for p in s.split('\n') if p.strip()]
    return parts

def _expand_ends_with_terminal(s: str) -> bool:
    return bool(re.search(r'(ë‹¤\.|ìš”\.|ë‹ˆë‹¤\.)\s*$|[.!?â€¦]\s*$|[â€â€™"\')\]ã€‘ã€‰ã€‹ã€ã€]\s*$', s or ''))

def _expand_crop_to_last_boundary(s: str) -> str:
    """ë§ˆì§€ë§‰ ë¬¸ì¥ ê²½ê³„(ë§ˆì¹¨í‘œ/ë”°ì˜´í‘œ ë“±)ì—ì„œ ì»·."""
    if not s:
        return s
    m = list(re.finditer(r'(ë‹¤\.|ìš”\.|ë‹ˆë‹¤\.)|[.!?â€¦]|[â€â€™"\')\]ã€‘ã€‰ã€‹ã€ã€]', s))
    return s if not m else s[:m[-1].end()]

def _expand_smart_trim_to_chars(text: str, max_chars: int) -> str:
    """ë¬¸ì¥ ê²½ê³„ ìœ ì§€í•˜ë©° ê¸€ì ìƒí•œì— ë§ì¶¤. ì‹¤íŒ¨ ì‹œ í•˜ë“œ ì»·."""
    if len(text) <= max_chars:
        return text
    parts = _expand_split_sentences_kor(text)
    out, total = [], 0
    for p in parts:
        if not _expand_ends_with_terminal(p):
            continue
        add = len(p) + (1 if out else 0)
        if total + add > max_chars:
            break
        out.append(p)
        total += add
    return ("\n".join(out).rstrip() if out else text[:max_chars].rstrip())

def _expand_est_tokens_for_chars(chars: int) -> int:
    """ëŒ€ëµì ì¸ í† í° ì˜ˆì‚°(í•œê¸€ ê¸°ì¤€ ì—¬ìœ ìˆê²Œ)."""
    return max(128, int(chars / 1.6) + 96)

def _expand_llm(client, messages, max_chars: int, temperature=0.35):
    """Chat Completions ë˜í¼: max_tokensë¥¼ ê¸€ììˆ˜ ê¸°ë°˜ìœ¼ë¡œ ì•ˆì „ ì„¤ì •."""
    max_tokens = _expand_est_tokens_for_chars(max_chars)
    resp = client.chat.completions.create(
        model="gpt-4",                 # â† í•„ìš”ì‹œ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸ëª…ìœ¼ë¡œ í†µì¼
        messages=messages,
        temperature=temperature,
        max_tokens=max_tokens,
    )
    choice = resp.choices[0]
    # ì¼ë¶€ SDKì—ì„œ finish_reason ì ‘ê·¼ ë°©ë²•ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìœ¼ë¯€ë¡œ getattr ì‚¬ìš©
    finish = getattr(choice, "finish_reason",
                     getattr(choice, "finish_reason", None))
    text = (choice.message.content or "").strip()
    return text, finish

def _expand_count_sents(s: str) -> int:
    return len(_expand_split_sentences_kor(s or ""))


class InformalInput(BaseModel):
    content: str
    ending: Optional[str] = None  # 'hada' | 'haetda' | 'hae'

class ExpandInput(BaseModel):
    content: str
    length_boost: int = 20
    length_level: Optional[str] = None
    add_sentences: int = 0

    class Config:
        extra = "ignore"

def _clamp(v, lo, hi):
    return max(lo, min(v, hi))

def _split_sentences_kor(text: str):
    """í•œêµ­ì–´/ì˜ë¬¸ í˜¼ìš© ê°„ë‹¨ ë¶„ë¦¬: ë§ˆì¹¨í‘œë¥˜/ì¢…ê²°í˜• + ê°œí–‰ ê¸°ì¤€."""
    text = re.sub(r'\s*\n+\s*', '\n', text.strip())
    s = re.sub(r'([\.!?â€¦])\s+', r'\1\n', text)
    s = re.sub(r'(ë‹¤\.|ìš”\.|ë‹ˆë‹¤\.)\s+', r'\1\n', s)
    return [p.strip() for p in s.split('\n') if p.strip()]

def _smart_trim_to_chars(text: str, max_chars: int) -> str:
    """ë¬¸ì¥ ë‹¨ìœ„ë¡œ í•©ì¹˜ë©´ì„œ ìƒí•œ ì´í•˜ë¡œ ìœ ì§€(ë¶ˆì™„ì „ ë§ˆì§€ë§‰ ë¬¸ì¥ì€ ë²„ë¦¼)."""
    if len(text) <= max_chars:
        return text
    parts = _split_sentences_kor(text)
    out, total = [], 0
    for p in parts:
        # ì™„ê²° ë¬¸ì¥ë§Œ ì¶”ê°€
        if not _ends_with_terminal(p):
            continue
        if total + len(p) + (1 if out else 0) > max_chars:
            break
        out.append(p)
        total += len(p) + (1 if out else 0)
    # ì—¬ì „íˆ ë¹„ë©´ í•˜ë“œì»·
    return ("\n".join(out).rstrip() if out else text[:max_chars].rstrip())

def _ends_with_terminal(s: str) -> bool:
    """ë¬¸ì¥ ì™„ê²° íŒë‹¨(í•œêµ­ì–´ ì¢…ê²°/ë¬¸ì¥ë¶€í˜¸/ë‹«í˜ë¬¸ì)."""
    return bool(re.search(r'(ë‹¤\.|ìš”\.|ë‹ˆë‹¤\.)\s*$|[.!?â€¦]\s*$|[â€â€™"\')\]ã€‘ã€‰ã€‹ã€ã€]\s*$', s))

def _crop_to_last_boundary(s: str) -> str:
    """ë§ˆì§€ë§‰ ë¬¸ì¥ ê²½ê³„ê¹Œì§€ë§Œ ë‚¨ê¹€."""
    m = list(re.finditer(r'(ë‹¤\.|ìš”\.|ë‹ˆë‹¤\.)|[.!?â€¦]|[â€â€™"\')\]ã€‘ã€‰ã€‹ã€ã€]', s))
    return s if not m else s[:m[-1].end()]

# ë¬¸ì„œ ì´ë¯¸ì§€ í…ìŠ¤íŠ¸ ì¶”ì¶œ ê´€ë ¨

def should_ocr(img_bytes: bytes, min_wh: int = 28) -> bool:
    try:
        from PIL import Image
        im = Image.open(io.BytesIO(img_bytes))
        w, h = im.size
        return (w >= min_wh and h >= min_wh)
    except Exception:
        return False
    
def ocr_image_bytes(img_bytes: bytes) -> str:
    if not img_bytes:
        return ""
 
    if vision_client is None:
        print("[OCR] vision_client is None (check GOOGLE_APPLICATION_CREDENTIALS_JSON or GOOGLE_APPLICATION_CREDENTIALS)")
        return ""
    try:
        image = vision.Image(content=img_bytes)
        resp = vision_client.text_detection(image=image)
        raw = ""
        if getattr(resp, "full_text_annotation", None):
            raw = resp.full_text_annotation.text or ""
        elif resp.text_annotations:
            raw = resp.text_annotations[0].description or ""
        return clean_ocr_text(raw)
    except Exception as e:
        print("âš ï¸ OCR ì‹¤íŒ¨:", e)
        return ""

def extract_pdf_in_reading_order(pdf_path: str) -> str:
    """í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ ë¸”ë¡ì„ í˜ì´ì§€ ìˆœì„œ ë° ì¢Œí‘œ ìˆœìœ¼ë¡œ ì„ì–´ ì¶œë ¥"""
    doc = fitz.open(pdf_path)
    parts = []
    for pno in range(len(doc)):
        page = doc[pno]
        # PyMuPDF dict: blocks = [{ "type":0|1, "bbox":[x0,y0,x1,y1], ... }]
        blocks = page.get_text("dict").get("blocks", [])
        # (type, y0, x0) ê¸°ì¤€ìœ¼ë¡œ ì•ˆì • ì •ë ¬
        blocks.sort(key=lambda b: (round(b["bbox"][1], 1), round(b["bbox"][0], 1)))
        parts.append(f"\n--- [p.{pno+1}] ---")
        for b in blocks:
            btype = b.get("type", 0)
            x0, y0, x1, y1 = b["bbox"]
            if btype == 0:  # text
                # ë¸”ë¡ ë‚´ ë¼ì¸/ìŠ¤íŒ¬ ê²°í•©
                lines = []
                for l in b.get("lines", []):
                    line_text = "".join([s.get("text","") for s in l.get("spans",[])])
                    lines.append(line_text)
                text = "\n".join([t.strip() for t in lines if t and t.strip()])
                if text:
                    parts.append(text)
            elif btype == 1:  # image
                # í•´ë‹¹ bbox ì˜ì—­ë§Œ ë Œë”ë§í•´ì„œ OCR
                rect = fitz.Rect(x0, y0, x1, y1)
                pix = page.get_pixmap(clip=rect, dpi=200)  # dpi ì¡°ì ˆ ê°€ëŠ¥(í’ˆì§ˆ/ì†ë„ íŠ¸ë ˆì´ë“œì˜¤í”„)
                img_bytes = pix.tobytes("png")
                try:
                    ocr = ocr_image_bytes(img_bytes).strip()
                except Exception:
                    ocr = ""
                if ocr:
                    parts.append("[ğŸ“· ì´ë¯¸ì§€ OCR]\n" + ocr)
    return "\n".join(parts).strip()
# ---------------------------
# í¬ë§·ë³„ ì¶”ì¶œê¸° (ë³¸ë¬¸ + ë‚´ì¥ ì´ë¯¸ì§€)
# ê° í•¨ìˆ˜ëŠ” (ë³¸ë¬¸í…ìŠ¤íŠ¸, ì´ë¯¸ì§€OCRë¦¬ìŠ¤íŠ¸) íŠœí”Œ ë°˜í™˜
# ---------------------------
def extract_from_image(raw: bytes) -> Tuple[str, List[str]]:
    # ë‹¨ì¼ ì´ë¯¸ì§€ íŒŒì¼ ìì²´ OCR
    return "", [ocr_image_bytes(raw)]

def extract_from_txt(raw: bytes) -> Tuple[str, List[str]]:
    return detect_text_encoding_and_decode(raw).strip(), []

def extract_from_pdf(raw: bytes) -> Tuple[str, List[str]]:
    text_parts, ocr_parts = [], []
    doc = fitz.open(stream=raw, filetype="pdf")
    for page in doc:
        text_parts.append(page.get_text())
        for img in page.get_images(full=True):
            xref = img[0]
            try:
                meta = doc.extract_image(xref)
                img_bytes = meta.get("image", b"")
                if img_bytes and should_ocr(img_bytes):
                    txt = ocr_image_bytes(img_bytes).strip()
                    if txt:
                        ocr_parts.append(txt)
            except Exception as e:
                print("pdf image extract err:", e)
    return "\n".join(text_parts).strip(), ocr_parts

def extract_from_docx(raw: bytes) -> Tuple[str, List[str]]:
    import zipfile, io
    text_parts, ocr_parts = [], []
    # 1) ë³¸ë¬¸ í…ìŠ¤íŠ¸
    try:
        d = Document(io.BytesIO(raw))
        for p in d.paragraphs:
            text_parts.append(p.text or "")
    except Exception as e:
        print("docx text parse err:", e)
    # 2) ë‚´ì¥ ì´ë¯¸ì§€ (ZIP ìŠ¤ìº”)
    try:
        found = 0
        with zipfile.ZipFile(io.BytesIO(raw)) as zf:
            for name in zf.namelist():
                low = name.lower()
                if low.startswith("word/media/") and low.split(".")[-1] in (
                    "png","jpg","jpeg","bmp","gif","tif","tiff","webp"
                ):
                    ocr_parts.append(ocr_image_bytes(zf.read(name)))
                    found += 1
                print(f"[DOCX] media images found: {found}, ocred: {sum(1 for t in ocr_parts if t)}")
    except Exception as e:
        print("docx media zip scan err:", e)
    return "\n".join(text_parts).strip(), [t for t in ocr_parts if t]

def extract_from_pptx(raw: bytes) -> Tuple[str, List[str]]:
    import zipfile, io
    text_parts, ocr_parts = [], []
    # 1) ë³¸ë¬¸ í…ìŠ¤íŠ¸
    try:
        prs = Presentation(io.BytesIO(raw))
        for slide in prs.slides:
            for shape in slide.shapes:
                if getattr(shape, "has_text_frame", False):
                    text_parts.append(shape.text or "")
    except Exception as e:
        print("pptx text parse err:", e)
    # 2) ë‚´ì¥ ì´ë¯¸ì§€ (ZIP ìŠ¤ìº”)
    try:
        with zipfile.ZipFile(io.BytesIO(raw)) as zf:
            for name in zf.namelist():
                low = name.lower()
                if low.startswith("ppt/media/") and low.split(".")[-1] in (
                    "png","jpg","jpeg","bmp","gif","tif","tiff","webp"
                ):
                    ocr_parts.append(ocr_image_bytes(zf.read(name)))
    except Exception as e:
        print("pptx media zip scan err:", e)
    return "\n".join(text_parts).strip(), [t for t in ocr_parts if t]

def extract_from_xlsx(raw: bytes) -> Tuple[str, List[str]]:
    import zipfile, io
    text_parts, ocr_parts = [], []
    # 1) ì…€ í…ìŠ¤íŠ¸
    try:
        wb = load_workbook(io.BytesIO(raw), data_only=True)
        for ws in wb.worksheets:
            for row in ws.iter_rows(values_only=True):
                vals = [str(c) for c in row if c is not None]
                if vals:
                    text_parts.append("\t".join(vals))
    except Exception as e:
        print("xlsx text parse err:", e)
    # 2) ë‚´ì¥ ì´ë¯¸ì§€ (ZIP ìŠ¤ìº”)
    try:
        with zipfile.ZipFile(io.BytesIO(raw)) as zf:
            for name in zf.namelist():
                low = name.lower()
                if low.startswith("xl/media/") and low.split(".")[-1] in (
                    "png","jpg","jpeg","bmp","gif","tif","tiff","webp"
                ):
                    ocr_parts.append(ocr_image_bytes(zf.read(name)))
    except Exception as e:
        print("xlsx media zip scan err:", e)
    return "\n".join(text_parts).strip(), [t for t in ocr_parts if t]



def try_guess_image_from_bin(bin_bytes: bytes) -> bytes:
    """HWP OLE BinData ìŠ¤íŠ¸ë¦¼ì—ì„œ PNG/JPEG ì‹œê·¸ë‹ˆì²˜ë¥¼ ì°¾ì•„ ì˜ë¼ë‚´ê¸°"""
    if not bin_bytes:
        return b""
    sigs = [b"\x89PNG\r\n\x1a\n", b"\xff\xd8\xff"]  # PNG/JPEG
    for sig in sigs:
        idx = bin_bytes.find(sig)
        if idx != -1:
            return bin_bytes[idx:]
    return b""

def extract_from_hwp_images_only(raw: bytes) -> Tuple[str, List[str]]:
    """
    HWP (OLE Compound)ì—ì„œ BinDataë¥˜ ìŠ¤íŠ¸ë¦¼ë§Œ ë’¤ì ¸ì„œ ì´ë¯¸ì§€ OCR.
    ë³¸ë¬¸ í…ìŠ¤íŠ¸ëŠ” ë³„ë„ íŒŒì„œ(hwp5txt)ê°€ ì—†ìœ¼ë©´ ìƒëµ.
    """
    ocr_parts = []
    with tempfile.NamedTemporaryFile(delete=False, suffix=".hwp") as tmp:
        tmp.write(raw)
        tmp.flush()
        path = tmp.name
    try:
        if not olefile.isOleFile(path):
            return "", []
        with olefile.OleFileIO(path) as ole:
            for entry in ole.listdir(streams=True, storages=True):
                # ì˜ˆ: ['BinData', 'Bin0001'] ë“±
                if any("Bin" in e or "BIN" in e for e in entry):
                    try:
                        stream = ole.openstream(entry).read()
                        img = try_guess_image_from_bin(stream)
                        if img:
                            ocr_parts.append(ocr_image_bytes(img))
                    except Exception as e:
                        print("hwp bin read err:", e)
    finally:
        try: os.remove(path)
        except: pass
    return "", [t for t in ocr_parts if t]

def extract_text_from_hwp_hwp5txt(raw: bytes) -> str:
    """
    (ì„ íƒ) hwp5txt CLIê°€ ì„¤ì¹˜ëœ í™˜ê²½ì—ì„œ HWP ë³¸ë¬¸ í…ìŠ¤íŠ¸ê¹Œì§€ ì¶”ì¶œ.
    ì„¤ì¹˜ê°€ ì•ˆë¼ ìˆìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜.
    """
    with tempfile.NamedTemporaryFile(delete=False, suffix=".hwp") as tmp:
        tmp.write(raw)
        tmp.flush()
        path = tmp.name
    try:
        # hwp5txt ê°€ PATH ì— ìˆì–´ì•¼ í•¨ (ë¦¬ëˆ…ìŠ¤ í™˜ê²½ ê¶Œì¥)
        out = subprocess.check_output(["hwp5txt", path], encoding="utf-8", errors="ignore")
        return out.strip()
    except Exception as e:
        print("hwp5txt not available or failed:", e)
        return ""
    finally:
        try: os.remove(path)
        except: pass

def extract_from_hwpx_zip(raw: bytes) -> Tuple[str, List[str]]:
    """
    HWPX(zip/xml)ì—ì„œ ë³¸ë¬¸ í…ìŠ¤íŠ¸ + ë‚´ì¥ ì´ë¯¸ì§€ OCRì„ í•¨ê»˜ ì¶”ì¶œ
    - í…ìŠ¤íŠ¸: Contents ì•„ë˜ xmlì—ì„œ { * }t / { * }p ë“± í…ìŠ¤íŠ¸ ë…¸ë“œ ëª¨ìœ¼ê¸°
    - ì´ë¯¸ì§€: Contents/Resources/* í•˜ìœ„ ì´ë¯¸ì§€ OCR
    """
    import zipfile, io, re
    text_parts, ocr_parts = [], []

    def _append_text(txt: str):
        t = (txt or "").strip()
        if t:
            text_parts.append(t)

    try:
        with zipfile.ZipFile(io.BytesIO(raw)) as zf:
            # 1) ì´ë¯¸ì§€ OCR (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
            for name in zf.namelist():
                low = name.lower()
                if ("/resources/" in low or low.startswith("contents/")) and low.split(".")[-1] in (
                    "png","jpg","jpeg","bmp","gif","tif","tiff","webp"
                ):
                    try:
                        ocr_txt = ocr_image_bytes(zf.read(name)).strip()
                        if ocr_txt:
                            ocr_parts.append(ocr_txt)
                    except Exception as e:
                        print("hwpx image ocr err:", e)

            # 2) ë³¸ë¬¸ í…ìŠ¤íŠ¸: Contents/*.xml íŒŒì‹±
            for name in zf.namelist():
                low = name.lower()
                if not (low.startswith("contents/") and low.endswith(".xml")):
                    continue
                try:
                    xml_bytes = zf.read(name)
                    # ê°€ë” ì¸ì½”ë”©/ì—”í‹°í‹° ë¬¸ì œê°€ ìˆì–´ errors='ignore'
                    xml_text = xml_bytes.decode("utf-8", errors="ignore")
                    # XML íŒŒì‹±
                    try:
                        root = ET.fromstring(xml_text)
                    except Exception:
                        # ìµœí›„ ìˆ˜ë‹¨: íƒœê·¸ ì œê±° ëŸ¬í”„ íŒŒì‹±(ê¶Œì¥X)
                        rough = re.sub(r"<[^>]+>", " ", xml_text)
                        _append_text(re.sub(r"\s+", " ", rough))
                        continue

                    # ë³´í†µ {ns}t ê°€ í…ìŠ¤íŠ¸ ëŸ°, {ns}p ê°€ ë¬¸ë‹¨
                    # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì™€ì¼ë“œì¹´ë“œ ì‚¬ìš©
                    # 1) ëŸ° í…ìŠ¤íŠ¸ ìš°ì„ 
                    for node in root.findall(".//{*}t"):
                        if node.text:
                            _append_text(node.text)

                    # 2) ë¬¸ë‹¨ ë‹¨ìœ„ ë³´ê°•(í…ìŠ¤íŠ¸ê°€ ê±°ì˜ ì—†ì„ ê²½ìš° ëŒ€ë¹„)
                    #   ë¬¸ë‹¨ ì•ˆì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ í•©ì¹¨
                    for p in root.findall(".//{*}p"):
                        buf = []
                        for tnode in p.findall(".//{*}t"):
                            if tnode.text:
                                buf.append(tnode.text.strip())
                        line = " ".join(buf).strip()
                        if line:
                            _append_text(line)

                except Exception as e:
                    print("hwpx xml parse err:", name, e)

    except Exception as e:
        print("hwpx zip scan err:", e)

    body = "\n".join(text_parts).strip()
    return body, [t for t in ocr_parts if t]

def detect_text_encoding_and_decode(b: bytes) -> str:
    for enc in ("utf-8", "cp949", "euc-kr", "latin1"):
        try:
            return b.decode(enc)
        except Exception:
            pass
    return ""

# ---------------------------
# ë©”ì¸ ë””ìŠ¤íŒ¨ì²˜
# ---------------------------
def extract_all_text_and_images(binary: bytes, filename: str) -> str:
    ext = (filename or "").lower().split(".")[-1]
    body, ocr_list = "", []

    try:
        if ext in ["png","jpg","jpeg","bmp","gif","tif","tiff","webp"]:
            body, ocr_list = extract_from_image(binary)

        elif ext == "pdf":
            body = extract_pdf_in_reading_order_bytes(binary)  # ìˆœì„œ ë³´ì¡´
            ocr_list = []

        elif ext == "docx":
            body, ocr_list = extract_from_docx(binary)

        elif ext == "pptx":
            body, ocr_list = extract_from_pptx(binary)

        elif ext == "xlsx":
            body, ocr_list = extract_from_xlsx(binary)

        elif ext == "txt":
            body, _ = extract_from_txt(binary)

        elif ext == "hwpx":
            body, ocr_list = extract_from_hwpx_zip(binary)

        elif ext == "hwp":
            body = extract_text_from_hwp_hwp5txt(binary)  # ì—†ìœ¼ë©´ ë¹ˆë¬¸ìì—´
            _, ocr_list = extract_from_hwp_images_only(binary)

        else:
            body = detect_text_encoding_and_decode(binary)

    except Exception as e:
        print("parse error:", type(e).__name__, e)

    body = (body or "").strip()
    ocr_text = "\n\n".join([t for t in (ocr_list or []) if t]).strip()

    if body and ocr_text:
        return f"{body}\n\n[ğŸ“· ì´ë¯¸ì§€ OCR]\n{ocr_text}"
    elif ocr_text:
        return f"[ğŸ“· ì´ë¯¸ì§€ OCR]\n{ocr_text}"
    else:
        return body

    
def extract_office_like_bytes(binary: bytes, filename: str) -> str:
    ext = os.path.splitext(filename)[1].lower()
    body_parts = []
    ocr_parts = []

    if ext == ".docx":
        # python-docx
        from docx import Document
        buf = io.BytesIO(binary)
        doc = Document(buf)
        body_parts.append("\n".join([p.text for p in doc.paragraphs if p.text.strip()]))
        # ì´ë¯¸ì§€: zip ì—´ì–´ media/* ì¶”ì¶œ â†’ ocr_image_bytes
        ocr_parts += ocr_images_from_zip(buf, "word/media/")

    elif ext == ".pptx":
        # python-pptx
        from pptx import Presentation
        buf = io.BytesIO(binary)
        pres = Presentation(buf)
        for slide in pres.slides:
            for shape in slide.shapes:
                if hasattr(shape, "text") and shape.text:
                    body_parts.append(shape.text)
        ocr_parts += ocr_images_from_zip(buf, "ppt/media/")

    elif ext == ".xlsx":
        # openpyxl
        import openpyxl, tempfile
        buf = io.BytesIO(binary)
        wb = openpyxl.load_workbook(buf, data_only=True)
        for ws in wb.worksheets:
            rows = []
            for row in ws.iter_rows(values_only=True):
                vals = [str(v) for v in row if v not in (None, "")]
                if vals: rows.append("\t".join(vals))
            if rows:
                body_parts.append(f"[{ws.title}]\n" + "\n".join(rows))
        ocr_parts += ocr_images_from_zip(buf, "xl/media/")

    elif ext == ".hwpx":
        # zip(xml) + ì´ë¯¸ì§€
        buf = io.BytesIO(binary)
        ocr_parts += ocr_images_from_zip(buf, "Contents/Resources/")

        # ë³¸ë¬¸(xml íŒŒì‹±ì€ ì„ íƒ. ì´ë¯¸ êµ¬í˜„ë¼ ìˆìœ¼ë©´ ê·¸ ë¡œì§ í˜¸ì¶œ)

    elif ext == ".hwp":
        # olefile ë¡œ BinData ì´ë¯¸ì§€ OCR
        import olefile
        f = io.BytesIO(binary)
        ole = olefile.OleFileIO(f)
        for s in ole.listdir():
            if s[0] == 'BinData' and s[-1].lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):
                data = ole.openstream(s).read()
                txt = ocr_image_bytes(data).strip()
                if txt: ocr_parts.append(txt)
        # ë³¸ë¬¸ í…ìŠ¤íŠ¸ëŠ” hwp5txtê°€ ì—†ìœ¼ë©´ ìƒëµ/ê¸°ì¡´ ë¡œì§

    merged = "\n".join([t for t in ["\n".join(body_parts)] if t.strip()])
    if ocr_parts:
        if merged: merged += "\n\n[ğŸ“· ì´ë¯¸ì§€ OCR]\n" + "\n\n".join(ocr_parts)
        else:      merged  = "[ğŸ“· ì´ë¯¸ì§€ OCR]\n" + "\n\n".join(ocr_parts)
    return merged

def ocr_images_from_zip(buf: io.BytesIO, prefix: str) -> list[str]:
    import zipfile
    texts = []
    buf.seek(0)
    with zipfile.ZipFile(buf) as z:
        for name in z.namelist():
            low = name.lower()
            if name.startswith(prefix) and low.endswith((
                '.png','.jpg','.jpeg','.bmp','.gif','.webp','.tif','.tiff'
            )):
                img_bytes = z.read(name)
                if img_bytes and should_ocr(img_bytes):
                    txt = ocr_image_bytes(img_bytes).strip()
                    if txt:
                        texts.append(txt)
    return texts


def extract_pdf_in_reading_order_bytes(raw: bytes) -> str:
    try:
        doc = fitz.open(stream=raw, filetype="pdf")
    except Exception as e:
        print("fitz open(pdf bytes) err:", e)
        return ""
    parts = []
    for i in range(len(doc)):
        page = doc[i]
        blocks = page.get_text("dict").get("blocks", [])
        blocks.sort(key=lambda b: (round(b["bbox"][1],1), round(b["bbox"][0],1)))
        parts.append(f"\n--- [p.{i+1}] ---")
        for b in blocks:
            t = b.get("type", 0)
            x0,y0,x1,y1 = b["bbox"]
            if t == 0:
                lines = []
                for l in b.get("lines", []):
                    lines.append("".join(s.get("text","") for s in l.get("spans",[])))
                txt = "\n".join(t.strip() for t in lines if t and t.strip())
                if txt: parts.append(txt)
            elif t == 1:
                rect = fitz.Rect(x0,y0,x1,y1)
                pix = page.get_pixmap(clip=rect, dpi=200)
                ocr = ocr_image_bytes(pix.tobytes("png")).strip()
                if ocr:
                    parts.append("[ğŸ“· ì´ë¯¸ì§€ OCR]\n"+ocr)
    return "\n".join(parts).strip()


load_dotenv()

app = FastAPI()


ALLOW_ORIGINS = [
    "http://127.0.0.1:5500",
    "http://localhost:5500",
    "http://127.0.0.1:3000",
    "http://localhost:3000",
    "http://127.0.0.1:8000",
    "http://localhost:8000",
    "https://hj-sp.github.io",
    "https://crystal-0109.github.io",
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOW_ORIGINS,
    allow_credentials=False,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],
    max_age=600,
)

@app.get("/whoami")
def whoami():
    return {
        "ok": True,
        "has_json_vision": bool(os.environ.get("GOOGLE_APPLICATION_CREDENTIALS_JSON")),
        "has_json_translate": bool(os.environ.get("GOOGLE_CREDENTIALS_JSON")),
        "has_path_var": bool(os.environ.get("GOOGLE_APPLICATION_CREDENTIALS")),
        "routes": [r.path for r in app.routes],
    }

@app.get("/cors-test")
def cors_test():
    return {"ok": True}


# ---- Vision (GOOGLE_APPLICATION_CREDENTIALS_JSON) ----
try:
    _vision_info = json.loads(
        os.environ["GOOGLE_APPLICATION_CREDENTIALS_JSON"])
    _vision_creds = service_account.Credentials.from_service_account_info(
        _vision_info)
    vision_client = vision.ImageAnnotatorClient(credentials=_vision_creds)
except Exception as e:
    # ì´ˆê¸°í™” ì‹¤íŒ¨ ì‹œ ë””ë²„ê·¸ ë¡œê·¸
    print("[Vision Init Error]", e)
    vision_client = None

# ---- Translate (GOOGLE_CREDENTIALS_JSON) ----
try:
    _trans_info = json.loads(os.environ["GOOGLE_CREDENTIALS_JSON"])
    _trans_creds = service_account.Credentials.from_service_account_info(
        _trans_info)
    translate_client = google_translate.Client(credentials=_trans_creds)
except Exception as e:
    print("[Translate Init Error]", e)
    translate_client = None

class TextInput(BaseModel):
    content: str
    style: str = "default"
    offset: int = 0
    source: str = "rewrite"

class StyleChangeRequest(BaseModel):
    text: str
    style: str


AudioSegment.converter = imageio_ffmpeg.get_ffmpeg_exe()  # íŒ¨í‚¤ì§€ ë‚´ë¶€ ffmpeg ì‚¬ìš©

MISTRAL_API_KEY_H = os.getenv("MISTRAL_API_KEY_H")
MISTRAL_API_KEY_S = os.getenv("MISTRAL_API_KEY_S")
AGENT_ID_SUMMARY = os.getenv("MISTRAL_AGENT_ID_SUMMARY")
AGENT_ID_REWRITE = os.getenv("MISTRAL_AGENT_ID_REWRITE")
AGENT_ID_GRAMMAR = os.getenv("MISTRAL_AGENT_ID_GRAMMAR")
AGENT_ID_GRAMMAR2 = os.getenv("MISTRAL_AGENT_ID_GRAMMAR2")
COHERE_API_KEY = os.getenv("COHERE_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)
PAPAGO_CLIENT_ID = os.getenv("PAPAGO_CLIENT_ID")
PAPAGO_CLIENT_SECRET = os.getenv("PAPAGO_CLIENT_SECRET")

@app.post("/searchExample")
async def search_example(data: TextInput):
    count = 5  # ê³ ì •
    prompt = f"""
    '{data.content}'ì´ë¼ëŠ” í‘œí˜„ì„ ë‹¤ì–‘í•œ ë¬¸ë§¥ê³¼ ìƒí™© ì†ì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ ì‚¬ìš©í•˜ëŠ” ì˜ˆë¬¸ì„ {count}ê°œ ë§Œë“¤ì–´ì¤˜.
    {'ì•ì—ì„œ ì œê³µëœ ì˜ˆë¬¸ê³¼ ê²¹ì¹˜ì§€ ì•Šê²Œ' if data.offset > 0 else ''}
    ê° ì˜ˆë¬¸ì€ ë¬¸ë§¥ì´ í’ë¶€í•´ì•¼ í•˜ë©°, ë¬¸ì¥ ê¸¸ì´ëŠ” 30ìì—ì„œ 100ì ì‚¬ì´ë¡œ ë‹¤ì–‘í•˜ê²Œ ì‘ì„±í•´ì¤˜.
    ëª¨ë“  ì˜ˆë¬¸ì€ ë²ˆí˜¸ë¥¼ ë§¤ê¸°ê³ , ë²ˆí˜¸ë³„ë¡œ ì¤„ë°”ê¿ˆí•´ì„œ êµ¬ë¶„í•´ì¤˜.
    """

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "ë„ˆëŠ” êµ­ì–´ ì˜ˆë¬¸ ìƒì„± ë„ìš°ë¯¸ì•¼."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7
        )
        output = response.choices[0].message.content
        return {"result": output}
    except Exception as e:
        return {"error": f"GPT í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"}


@app.post("/gptStyleChange")
async def gpt_style_change(request: Request):
    body = await request.json()

    text = body.get('text')
    style = body.get('style')

    if not text or not style:
        print("â— textë‚˜ styleì´ ë¹„ì–´ìˆìŒ")
        return {"error": "text ë˜ëŠ” styleì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}

    style = style.lower()

    style_instructions = {
        "formal": "ë¬¸ì¥ì„ ê²©ì‹ ìˆê³  ì •ì¤‘í•˜ê²Œ ë°”ê¿”ì¤˜.",
        "casual": "ë¬¸ì¥ì„ ì¹œê·¼í•˜ê³  ì¼ìƒì ì¸ ë§íˆ¬ë¡œ ë°”ê¿”ì¤˜.",
        "literary": "ë¬¸ì¥ì„ ë¬¸í•™ì ìœ¼ë¡œ í’ˆê²© ìˆê²Œ ë‹¤ì‹œ ì¨ì¤˜.",
        "academic": "ë¬¸ì¥ì„ ì „ë¬¸ì ì´ê³  í•™ìˆ ì ì¸ í‘œí˜„ìœ¼ë¡œ ë°”ê¿”ì¤˜."
    }

    instruction = style_instructions.get(style)

    if instruction is None:
        print(f"â— ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤íƒ€ì¼: {style}")
        return {"error": f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ìŠ¤íƒ€ì¼ì…ë‹ˆë‹¤. (ì„œë²„ê°€ ë°›ì€ style: {style})"}

    full_prompt = f"ì•„ë˜ ë¬¸ì¥ì„ {instruction}\n\n'{text}'"

    try:
        completion = client.chat.completions.create(
            model="gpt-4",
            messages=[
                {"role": "system",
                    "content": "ë„ˆëŠ” ë¬¸ì²´ë¥¼ ë³€í™˜í•˜ëŠ” ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì•¼. ë¬¸ì²´ ë³€ê²½ì‹œ ë¹„ì†ì–´ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆ."},
                {"role": "user", "content": full_prompt}
            ],
            temperature=0.7
        )
        output = completion.choices[0].message.content
        print(output)

        # ê¸€ ì• ë’¤ ë”°ì˜´í‘œ ì œê±°
        output = output[1:-1] if len(
            output) >= 2 and output[0] == output[-1] and output[0] in ('"', "'") else output
        print(output)

        return {"styled_text": output}
    except Exception as e:
        return {"error": f"GPT í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"}

@app.post("/mistralRewrite")
async def mistral_rewrite(content: TextInput):
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY_H}",
        "Content-Type": "application/json"
    }
    count = 1

    prompt = f"""ë„ˆëŠ” ì°½ì˜ì ì´ê³  ìœ ì—°í•œ ê¸€ì“°ê¸° ì²¨ì‚­ ë„ìš°ë¯¸ì•¼. ì•„ë˜ ê¸€ì„ ë°”íƒ•ìœ¼ë¡œ ë¦¬ë¼ì´íŒ…í•œ **ì˜ˆì‹œë¬¸ì„ ë°˜ë“œì‹œ í•˜ë‚˜ë§Œ** ì‘ì„±í•´ ì¤˜. ë‹¤ìŒ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ë”°ë¼ì•¼ í•´:

1. ë¬¸ì²´ì™€ ì˜ë¯¸ëŠ” ìœ ì§€í•˜ë˜,  
2. ë¬¸ì¥ êµ¬ì¡°(ì˜ˆ: ì–´ìˆœ, êµ¬ë¬¸ ìœ í˜•, ëŠ¥ë™/ìˆ˜ë™, ë¬¸ì¥ ê¸¸ì´)ë¥¼ ë‹¤ì–‘í•˜ê²Œ ë°”ê¾¸ê³ ,  
3. ë‹¨ì–´ ì„ íƒê³¼ ì–´íœ˜ ìŠ¤íƒ€ì¼(ì˜ˆ: ë¬˜ì‚¬ ì¤‘ì‹¬, ê°ì • ê°•ì¡°, ê°„ê²°ì²´, ë¬¸ì–´ì²´ ë“±)ì„ ë§¤ë²ˆ ë‹¤ë¥´ê²Œ ì¨ì¤˜.

ì¶œë ¥ í˜•ì‹ì€ ë‹¤ìŒê³¼ ê°™ì•„:

(ì—¬ê¸°ì— ë¦¬ë¼ì´íŒ…ëœ ë¬¸ì¥)

ì•„ë¬´ ì„¤ëª… ì—†ì´ ì˜ˆì‹œë¬¸ í•˜ë‚˜ë§Œ ë³´ì—¬ì¤˜.
ì›ë¬¸: {content.content}
"""

    payload = {
        "agent_id": AGENT_ID_REWRITE,
        "messages": [
            {"role": "user", "content": prompt}
        ]
    }

    response = requests.post(
        "https://api.mistral.ai/v1/agents/completions",
        headers=headers,
        json=payload
    )

    if response.status_code != 200:
        return {"error": f"HTTP ì˜¤ë¥˜: {response.status_code}", "detail": response.text}

    result = response.json()

    try:
        message = result["choices"][0]["message"]["content"]
    except (KeyError, IndexError) as e:
        return {"error": "ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜", "detail": str(e), "raw_response": result}

    return {"result": message}

@app.post("/summary")
async def summarize(content: TextInput):
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY_H}",
        "Content-Type": "application/json"
    }
    payload = {
        "agent_id": AGENT_ID_SUMMARY,
        "messages": [
            {"role": "user", "content": f"ë‹¤ìŒ ê¸€ì„ ìµœëŒ€í•œ ê°„ê²°í•˜ê²Œ ìš”ì•½í•´ì¤˜. ëŒ€ì‹  í•µì‹¬ë‚´ìš©ì€ í¬í•¨í•´ì¤˜:\n\n{content.content}"}
        ]
    }
    response = requests.post(
        "https://api.mistral.ai/v1/agents/completions", headers=headers, json=payload)
    result = response.json()
    try:
        message = result["choices"][0]["message"]["content"]
    except (KeyError, IndexError):
        return {"error": "Mistral ìš”ì•½ ì˜¤ë¥˜"}
    return {"result": message}

@app.post("/expand")
async def expand(payload: ExpandInput):
    try:
        text = (payload.content or "").strip()
        if not text:
            raise HTTPException(status_code=400, detail="content is empty")

        # 1) ê¸¸ì´ ì¦ê°€ í¼ì„¼íŠ¸ í™•ì •
        level_map = {'low': 20, 'medium': 50, 'high': 80, 'xhigh': 100}
        if getattr(payload, "length_level", None):
            boost_in = level_map.get(payload.length_level.lower(), 50)
        else:
            boost_in = int(getattr(payload, "length_boost", 20) or 20)

        allowed = [20, 50, 70, 80, 100]
        # í—ˆìš©ê°’ì— ìŠ¤ëƒ… â†’ ë¯¸ì„¸ê°’ë„ ê·¼ì ‘ í—ˆìš©ìœ¼ë¡œ ë§¤í•‘
        boost = boost_in if boost_in in allowed else min(
            allowed, key=lambda x: abs(x - boost_in)
        )

        # 2) ì…ë ¥ ê¸¸ì´/ë¬¸ì¥ìˆ˜ ì¸¡ì • (kss)
        orig_chars = len(text)
        orig_sents = count_ko_sentences(text)
        short_input = (orig_chars < 120) or (orig_sents <= 2)

        # 3) ëª©í‘œ/ìµœì†Œ/ìµœëŒ€ ê¸€ììˆ˜ ì„¤ì •
        target_chars = int(orig_chars * (1 + boost / 100.0))
        min_chars = int(orig_chars * (1 + (boost / 100.0) * 0.95))
        max_chars = int(orig_chars * (1 + boost / 100.0 + 0.08))

        if short_input:
            # ì§§ì€ ì…ë ¥ì€ ë°”ë‹¥/ìƒí•œì„ ì˜¬ë ¤ ìì—°ìŠ¤ëŸ¬ìš´ ë¶„ëŸ‰ í™•ë³´
            floor_min = orig_chars + (120 if boost >= 70 else 80)
            floor_target = floor_min + 60
            floor_max = floor_target + 160
            min_chars = max(min_chars, floor_min)
            target_chars = max(target_chars, floor_target)
            max_chars = max(max_chars, floor_max)

        # 4) ë¬¸ì¥ ì¶”ê°€ ì˜µì…˜
        add_n = max(0, min(int(getattr(payload, "add_sentences", 0) or 0), 50))

        # ì§§ì€ ì…ë ¥ + add_n ë¯¸ì§€ì • ì‹œ ê¸°ë³¸ 1~2ë¬¸ì¥ ë³´ê°•
        if short_input and add_n == 0:
            add_n = 2 if boost >= 70 else 1

        if add_n > 0:
            # ë¬¸ì¥ ì¶”ê°€ ì‹œ ì˜ˆìƒ ê¸€ììˆ˜(ë¬¸ì¥ë‹¹ 70ì ê¸°ì¤€)ë¡œ ì˜ˆì‚° ìƒí–¥
            extra_chars = add_n * 70
            min_chars = max(min_chars, int(orig_chars + extra_chars * 0.8))
            target_chars = max(target_chars, min_chars + 60)
            max_chars = max(max_chars, int(orig_chars + extra_chars * 1.4))

        # ë¶ˆë³€ì„± ë³´ì¥
        if min_chars > max_chars:
            max_chars = min_chars + 120
        if target_chars > max_chars:
            target_chars = max(min_chars, max_chars - 60)

        # 5) 1ì°¨ ìƒì„±
        system_msg = "ë‹¹ì‹ ì€ í•œêµ­ì–´ ê¸€ì„ ìì—°ìŠ¤ëŸ½ê³  ëª…í™•í•˜ê²Œ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."
        guide = [
            "ì›ë¬¸ ì˜ë¯¸ë¥¼ ìœ ì§€í•˜ê³  ì „ê°œë¥¼ ë§¤ë„ëŸ½ê²Œ í™•ì¥í•˜ë¼.",
            "ë‹¨ìˆœí•œ ë°”ê¿”ì“°ê¸°(íŒ¨ëŸ¬í”„ë ˆì´ì¦ˆ)ë§Œ í•˜ì§€ ë§ê³ , ìƒˆë¡œìš´ ì„¤ëª…/ì´ìœ /ì˜ˆì‹œ/ì „í™˜ì„ ë§ë¶™ì—¬ë¼.",
            f"ìµœì†Œ {min_chars}ì ì´ìƒ, ìµœëŒ€ {max_chars}ì ì´í•˜ë¥¼ ì—„ìˆ˜í•˜ë¼.",
            f"ëª©í‘œ ê¸¸ì´: ì•½ {target_chars}ì.",
            "ë¶ˆí•„ìš”í•œ ë„ì…/ê²°ë¡ /ì¤‘ë³µ ìš”ì•½ì„ í”¼í•˜ë¼.",
            "ëª¨ë“  ë¬¸ì¥ì€ ì™„ê²°í˜•(â€¦ë‹¤./â€¦ìš”./â€¦ì…ë‹ˆë‹¤.)ìœ¼ë¡œ ëë‚´ë¼.",
        ]
        if add_n > 0:
            per_sent_buf = 130  # ë¬¸ì¥ í•˜ë‚˜ë‹¹ ì•ˆì „ ë²„í¼
            max_chars += add_n * per_sent_buf
            guide.append(f"ì›ë¬¸ ë‚´ìš©ì€ ìœ ì§€í•˜ë˜, **ìµœì†Œ {add_n}ë¬¸ì¥**ì„ ìƒˆë¡œ ì¶”ê°€í•˜ë¼.")

        user_prompt = f"[ì›ë¬¸]\n{text}\n\n[ì§€ì‹œ]\n- " + "\n- ".join(guide)

        out, finish = _expand_llm(
            client,
            [{"role": "system", "content": system_msg},
             {"role": "user", "content": user_prompt}],
            max_chars=max_chars,
            temperature=0.35
        )

        if len(out) > max_chars:
            out = _expand_smart_trim_to_chars(out, max_chars)

        # 6) ëë§ºìŒ ë³´ì •
        if not _expand_ends_with_terminal(out) or finish == "length":
            remain = max(0, max_chars - len(out))
            if remain > 24:
                tail_ctx = out[-500:] if len(out) > 500 else out
                tail_prompt = (
                    f"{tail_ctx}\n\n"
                    "ìœ„ ê¸€ì˜ ë§ˆì§€ë§‰ì„ ìì—°ìŠ¤ëŸ½ê²Œ ëë§ºìœ¼ì„¸ìš”.\n"
                    "- í•œ ë¬¸ì¥ë§Œ ì¶œë ¥\n"
                    "- ìƒˆë¡œìš´ ì£¼ì¥/ì˜ˆì‹œ ì¶”ê°€ ê¸ˆì§€, ì• ë§¥ë½ë§Œ ì™„ê²°\n"
                    f"- ìµœëŒ€ ê¸¸ì´ {min(140, remain)}ì\n"
                    "- ì™„ê²°í˜• ì¢…ê²°ì–´ë¯¸ë¡œ ëë‚´ì„¸ìš”(â€¦ë‹¤./â€¦ìš”./â€¦ì…ë‹ˆë‹¤.)."
                )
                tail, _ = _expand_llm(
                    client,
                    [{"role": "system", "content": "ê°„ê²°í•œ ë¬¸ì¥ ë§ˆë¬´ë¦¬ ë„ìš°ë¯¸"},
                     {"role": "user", "content": tail_prompt}],
                    max_chars=min(140, remain),
                    temperature=0.2
                )
                if tail:
                    sep = "" if out.endswith((" ", "\n")) else " "
                    out = (out + sep + tail).strip()
            if len(out) > max_chars:
                out = _expand_smart_trim_to_chars(out, max_chars)

        # 7) ìµœì†Œ ê¸€ììˆ˜ ë¯¸ë‹¬ ì‹œ ë³´ê°•
        tries = 0
        while len(out) < min_chars and tries < 2:
            need_chars = max(120, min(min_chars - len(out),
                             int((min_chars - len(out)) * 1.2)))
            add_guide = [
                "ê¸°ì¡´ ë¬¸ì¥ì€ ë°”ê¾¸ì§€ ë§ê³ , 'ì¶”ê°€ ë¬¸ì¥/ë¬¸ë‹¨'ë§Œ ì´ì–´ì„œ ì‘ì„±í•˜ë¼.",
                f"í˜„ì¬ ê¸¸ì´: {len(out)}ì, ëª©í‘œ ìµœì†Œ: {min_chars}ì â†’ ëŒ€ëµ {need_chars}ì ë³´ê°•.",
                "ì¤‘ë³µ ìš”ì•½Â·ë„ì…/ê²°ë¡  ì¬ì‘ì„± ê¸ˆì§€.",
                "ì™„ê²°í˜• ì¢…ê²°ì–´ë¯¸ë¡œ ëë‚´ë¼."
            ]
            cont_prompt = (
                f"[ì§€ê¸ˆê¹Œì§€ì˜ ì´ˆì•ˆ]\n{out}\n\n"
                "[ì§€ì‹œ]\n- " + "\n- ".join(add_guide) + "\n"
                "â€» ì¶œë ¥ì€ 'ì¶”ê°€ë˜ëŠ” ë‚´ìš©ë§Œ' ë°˜í™˜í•˜ì„¸ìš”."
            )
            remain_budget = max_chars - len(out)
            if remain_budget <= 60:
                break
            add_text, _ = _expand_llm(
                client,
                [{"role": "system", "content": "í™•ì¥ ë³´ê°• ë„ìš°ë¯¸"},
                 {"role": "user", "content": cont_prompt}],
                max_chars=min(remain_budget, max(220, need_chars + 140)),
                temperature=0.35
            )
            add_text = (add_text or "").strip()
            if len(add_text) > remain_budget:
                add_text = _expand_smart_trim_to_chars(add_text, remain_budget)
            if add_text:
                sep = "\n\n" if not out.endswith("\n") else "\n"
                out = (out + sep + add_text).strip()
            if len(out) > max_chars:
                out = _expand_smart_trim_to_chars(out, max_chars)
            if not _expand_ends_with_terminal(out):
                out = _expand_crop_to_last_boundary(out)
            tries += 1

        # 8) ë¬¸ì¥ ì¶”ê°€ ì •í™•ë„ ë£¨í”„ (kss ê¸°ë°˜)
        if add_n > 0:
            per_sent_buf = 130  # ë¬¸ì¥ í•˜ë‚˜ë‹¹ ì•ˆì „ ë²„í¼
            max_chars += add_n * per_sent_buf
            needed = (orig_sents + add_n) - count_ko_sentences(out)
            s_tries = 0
            while needed > 0 and s_tries < 4:
                remain_budget = max_chars - len(out)
                if remain_budget <= 80:
                    break

                per_sent_budget = 120
                ask_budget = min(remain_budget, needed * per_sent_budget + 40)

                cont_prompt = f"""
[ì§€ê¸ˆê¹Œì§€ì˜ ì´ˆì•ˆ]
{out}

[ì§€ì‹œ]
- ê¸°ì¡´ ë¬¸ì¥ì€ ìˆ˜ì •í•˜ì§€ ë§ê³  'ì´ì–´ ì“°ê¸°'ë§Œ í•˜ì„¸ìš”.
- **ì •í™•íˆ {needed}ê°œ ë¬¸ì¥**ì„ ì¶”ê°€í•˜ì„¸ìš”.
- ë²ˆí˜¸/ë¶ˆë¦¿/ë”°ì˜´í‘œ/ë¨¸ë¦¬ë§ ì—†ì´, ê° ë¬¸ì¥ì€ **í•œ ì¤„ì— í•œ ë¬¸ì¥**ë§Œ ì¶œë ¥í•˜ë ¤ ë…¸ë ¥í•˜ì„¸ìš”.
- ëª¨ë“  ë¬¸ì¥ì€ ì™„ê²°í˜•(â€¦ë‹¤./â€¦ìš”./â€¦ì…ë‹ˆë‹¤.)ìœ¼ë¡œ ëë‚´ì„¸ìš”.
- ë„ì…/ê²°ë¡ /ìš”ì•½/ì¤‘ë³µ ê¸ˆì§€, ì• ë§¥ë½ë§Œ ìì—°ìŠ¤ëŸ½ê²Œ ë³´ê°•í•˜ì„¸ìš”.
- ì¶œë ¥ì€ **ì¶”ê°€ë˜ëŠ” ë¬¸ì¥ë§Œ** ë°˜í™˜í•˜ì„¸ìš”.
""".strip()

                add_text, _ = _expand_llm(
                    client,
                    [
                        {"role": "system", "content": "ë¬¸ì¥ ì¶”ê°€ ì „ìš© ë³´ì¡°"},
                        {"role": "user", "content": cont_prompt}
                    ],
                    max_chars=ask_budget,
                    temperature=0.3
                )
                add_text = (add_text or "").strip()
                if not add_text:
                    s_tries += 1
                    continue

                # (1) kssë¡œ ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬
                cand_sents = split_ko_sentences(add_text)

                # (2) ë¶ˆë¦¿/ë²ˆí˜¸ ì œê±° + ì¢…ê²° ë³´ì •
                cleaned = []
                for s in cand_sents:
                    s = re.sub(r'^[\s\-\*\â€¢\Â·]+', '', s)      # ë¶ˆë¦¿ë¥˜ ì œê±°
                    s = re.sub(r'^\s*\d+[\.\)]\s*', '', s)     # ë²ˆí˜¸ ì œê±°
                    s = s.strip()
                    if not s:
                        continue
                    if not s.endswith(("ë‹¤.", "ìš”.", "ì…ë‹ˆë‹¤.", "?", "!", "â€¦", ".")):
                        s = s.rstrip(" ,;:") + "ë‹¤."
                    cleaned.append(s)

                if not cleaned:
                    s_tries += 1
                    continue

                # (3) í•„ìš”í•œ ê°œìˆ˜ë§Œ ì„ ë³„
                to_take = cleaned[:needed]

                # (4) ì˜ˆì‚° ì´ˆê³¼ ì‹œ ë’¤ì—ì„œ ë¬¸ì¥ ë‹¨ìœ„ë¡œ ì¤„ì´ê¸°
                room = remain_budget - (0 if out.endswith("\n") else 1)
                while to_take and len("\n".join(to_take)) > room:
                    to_take.pop()

                if not to_take:
                    s_tries += 1
                    continue

                # (5) ë³¸ë¬¸ì— ë¶™ì´ê¸°
                sep = "\n" if out.endswith("\n") else "\n\n"
                out = (out + sep + "\n".join(to_take)).strip()

                if len(out) > max_chars:
                    out = _expand_smart_trim_to_chars(out, max_chars)

                # (6) ë‚¨ì€ í•„ìš” ë¬¸ì¥ ì¬ê³„ì‚°
                needed = (orig_sents + add_n) - count_ko_sentences(out)
                s_tries += 1

            # (ì˜µì…˜) ë§ˆì§€ë§‰ ë¯¸ë‹¬ ë¬¸ì¥ ë³´ì • 1íšŒ
            final_needed = (orig_sents + add_n) - count_ko_sentences(out)
            remain_budget = max_chars - len(out)
            if final_needed > 0 and remain_budget > 60:
                per_sent_budget = 90
                ask_budget = min(
                    remain_budget, final_needed * per_sent_budget + 20)
                cont_prompt = f"""
[ì§€ê¸ˆê¹Œì§€ì˜ ì´ˆì•ˆ]
{out}

[ì§€ì‹œ]
- ê¸°ì¡´ ë¬¸ì¥ ìˆ˜ì • ê¸ˆì§€, ì´ì–´ì“°ê¸°ë§Œ.
- **ì •í™•íˆ {final_needed}ê°œ ë¬¸ì¥** ì¶”ê°€.
- ë²ˆí˜¸/ë¶ˆë¦¿ ì—†ì´ ìì—°ìŠ¤ëŸ¬ìš´ ì™„ê²°í˜• ë¬¸ì¥.
- ì¶œë ¥ì€ ì¶”ê°€ ë¬¸ì¥ë§Œ.
""".strip()
                add_text, _ = _expand_llm(
                    client,
                    [
                        {"role": "system", "content": "ë¬¸ì¥ ì¶”ê°€(ë§ˆê°) ë³´ì¡°"},
                        {"role": "user", "content": cont_prompt}
                    ],
                    max_chars=ask_budget,
                    temperature=0.25
                )
                lines = split_ko_sentences(add_text or "")
                take = lines[:final_needed]

                room = remain_budget - (0 if out.endswith("\n") else 1)
                while take and (len("\n".join(take)) > room):
                    take.pop()

                if take:
                    sep = "\n" if out.endswith("\n") else "\n\n"
                    out = (out + sep + "\n".join(take)).strip()
                    if len(out) > max_chars:
                        out = _expand_smart_trim_to_chars(out, max_chars)

        # 9) ìµœì¢… ìµœëŒ“ê°’ ë³´ì •
        if len(out) > max_chars:
            out = _expand_smart_trim_to_chars(out, max_chars)

        return {
            "result": out,
            "meta": {
                "orig_chars": orig_chars,
                "min_chars": min_chars,
                "max_chars": max_chars,
                "target_chars": target_chars,
                "requested_add_sentences": add_n,
                "final_chars": len(out),
                "final_sents": count_ko_sentences(out),
            }
        }

    except HTTPException:
        raise
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"error": f"/expand failed: {type(e).__name__}: {str(e)}"}
        )

@app.post("/mistralGrammar")
async def mistral_grammar(content: TextInput):
    start_time = time.perf_counter()  # ì²˜ë¦¬ ì‹œì‘ ì‹œì 
    headers = {
        "Authorization": f"Bearer {MISTRAL_API_KEY_S}",
        "Content-Type": "application/json"
    }
    payload = {
        "agent_id": AGENT_ID_GRAMMAR,
        "messages": [
            {"role": "user", "content": content.content}
        ]
    }

    response = requests.post(
        "https://api.mistral.ai/v1/agents/completions",
        headers=headers,
        json=payload
    )

    if response.status_code != 200:
        return {"error": f"HTTP ì˜¤ë¥˜: {response.status_code}", "detail": response.text}

    result = response.json()
    # print("Mistral ì‘ë‹µ:", result)

    try:
        message = result["choices"][0]["message"]["content"]
    except (KeyError, IndexError) as e:
        return {"error": "ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜", "detail": str(e), "raw_response": result}

    end_time = time.perf_counter()
    elapsed_time = end_time - start_time
    print(f"[ì´ ì²˜ë¦¬ ì‹œê°„] {elapsed_time:.2f}ì´ˆ")

    return {"result": message}


# @app.post("/mistralGrammar2")
# async def mistral_grammar2(content: TextInput):
#     start_time = time.perf_counter()  # ì²˜ë¦¬ ì‹œì‘ ì‹œì 
#     # ë¬¸ì¥ ë¶„ë¦¬ (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ë“±ìœ¼ë¡œ ë¶„ë¦¬)
#     sentences = split_sentences(content.content)
#     n = len(sentences)  # ë¬¸ì¥ ê°œìˆ˜(ë°°ì—´ í–‰ ê°œìˆ˜)
#     print(n)

#     # ì•ë’¤ ê³µë°± ì œê±°
#     sentences = [s.strip() for s in sentences if s.strip()]

#     # ní–‰ 3ì—´ ë°°ì—´ ìƒì„±: ì²« ì—´ì— ë¬¸ì¥, ë‚˜ë¨¸ì§€ ë‘ ì—´ì€ ë¹ˆ ë¬¸ìì—´ (ì›ë¬¸, êµì •ë¬¸, ë¯¸ìŠ¤íŠ¸ë„ ê²°ê³¼)
#     array = [[sentence, "", ""] for sentence in sentences]
#     for row in array:
#         print(row)

#     # T5 ëª¨ë¸ ë¡œë“œ
#     model = T5ForConditionalGeneration.from_pretrained(
#         "j5ng/et5-typos-corrector")
#     tokenizer = T5Tokenizer.from_pretrained("j5ng/et5-typos-corrector")

#     device = "cuda:0" if torch.cuda.is_available() else "cpu"

#     model = model.to(device)

#     for i in range(n):
#         # ì˜ˆì‹œ ì…ë ¥ ë¬¸ì¥
#         input_text = array[i][0]

#         # ì…ë ¥ ë¬¸ì¥ ì¸ì½”ë”©
#         input_encoding = tokenizer(
#             "ë§ì¶¤ë²•ì„ ê³ ì³ì£¼ì„¸ìš”: " + input_text, return_tensors="pt")

#         input_ids = input_encoding.input_ids.to(device)
#         attention_mask = input_encoding.attention_mask.to(device)

#         # T5 ëª¨ë¸ ì¶œë ¥ ìƒì„±
#         output_encoding = model.generate(
#             input_ids=input_ids,
#             attention_mask=attention_mask,
#             max_length=128,
#             num_beams=5,
#             early_stopping=True,
#         )

#         # ì¶œë ¥ ë¬¸ì¥ ë””ì½”ë”©
#         output_text = tokenizer.decode(
#             output_encoding[0], skip_special_tokens=True)

#         array[i][1] = output_text

#     # ì—­ìˆœìœ¼ë¡œ ì¸ë±ìŠ¤ë¥¼ ëŒë©´ì„œ ë§ì¶¤ë²•ì´ í‹€ë¦° ê²Œ ì—†ëŠ” ë¬¸ì¥ ì‚­ì œ
#     for i in reversed(range(len(array))):
#         if array[i][0] == array[i][1]:
#             del array[i]

#     for row in array:
#         print(row)

#     for i in range(len(array)):
#         mistral_input_text = f"1. {array[i][0]}\n2. {array[i][1]}"

#         headers = {
#             "Authorization": f"Bearer {MISTRAL_API_KEY_S}",
#             "Content-Type": "application/json"
#         }
#         payload = {
#             "agent_id": AGENT_ID_GRAMMAR2,
#             "messages": [
#                 {"role": "user", "content": mistral_input_text}
#             ]
#         }
#         response = requests.post(
#             "https://api.mistral.ai/v1/agents/completions",
#             headers=headers,
#             json=payload
#         )

#         if response.status_code != 200:
#             return {"error": f"HTTP ì˜¤ë¥˜: {response.status_code}", "detail": response.text}

#         result = response.json()

#         try:
#             message = result["choices"][0]["message"]["content"]
#             array[i][2] = message  # ì‘ë‹µ ê²°ê³¼
#             print(array[i][2])
#         except (KeyError, IndexError) as e:
#             return {"error": "ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜", "detail": str(e), "raw_response": result}

#     end_time = time.perf_counter()
#     elapsed_time = end_time - start_time
#     print(f"[ì´ ì²˜ë¦¬ ì‹œê°„] {elapsed_time:.2f}ì´ˆ")

#     return {"result": array, "arrayLen": len(array)}

def split_sentences(text):
    text = text.strip()
    if not text:
        return []

    # ë¬¸ì¥ ë êµ¬ë‘ì ì´ í•˜ë‚˜ë¼ë„ í¬í•¨ë¼ ìˆë‹¤ë©´ ê·¸ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
    if re.search(r'[.!?]', text):
        # ë§ˆì¹¨í‘œ/ëŠë‚Œí‘œ/ë¬¼ìŒí‘œ ê¸°ì¤€ìœ¼ë¡œ ë¬¸ì¥ ë¶„ë¦¬ (ìº¡ì²˜ ê·¸ë£¹ìœ¼ë¡œ í¬í•¨ì‹œì¼œì„œ ë¬¸ì¥ êµ¬ë‘ì ë„ ì‚´ë¦¼)
        parts = re.split(r'([.!?])', text)
        sentences = []
        for i in range(0, len(parts) - 1, 2):
            sentence = parts[i].strip() + parts[i + 1]  # ë¬¸ì¥ + êµ¬ë‘ì 
            if sentence.strip():
                sentences.append(sentence.strip())
        return sentences
    else:
        # ë§ˆì¹¨í‘œ/ëŠë‚Œí‘œ/ë¬¼ìŒí‘œ ì—†ìœ¼ë©´ í•œ ë¬¸ì¥ìœ¼ë¡œ ê°„ì£¼
        return [text]

# ê¸°ì¡´
# @app.post("/cohereHonorific")
# async def cohere_honorific(content: TextInput):
#     co = cohere.ClientV2(COHERE_API_KEY)
#     user_prompt = f"{content.content}\n\nì´ ê¸€ì—ì„œ ~ìŠµë‹ˆë‹¤. ì²˜ëŸ¼ ë†’ì„ë§ë¡œ ë°”ê¿”ì¤˜. ê·¸ë¦¬ê³  ê²°ê³¼ëŠ” ë”± ê¸€ë§Œ ë‚˜ì˜¤ê²Œ í•´ì¤˜."
#     response = co.chat(
#         model="command-a-03-2025",
#         messages=[{"role": "user", "content": user_prompt}]
#     )
#     full_text = response.message.content[0].text
#     return {"result": full_text}


@app.post("/cohereHonorific")
async def cohere_honorific(request: Request):
    body = await request.json()
    text = (body.get("content") or body.get("text") or "").strip()
    level = (body.get("level") or "hamnida").lower()
    if level not in ("haeyo", "hamnida"):
        level = "hamnida"

    if not text:
        return {"error": "content(text)ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."}

    style_map = {
        "haeyo": "ë¬¸ì¥ì„ ì •ì¤‘í•˜ì§€ë§Œ ëœ ê²©ì‹ ìˆëŠ” â€˜í•´ìš”ì²´(~ìš”)â€™ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¿”ì¤˜.",
        "hamnida": "ë¬¸ì¥ì„ ê³µì‹/ë¬¸ì–´ì²´ì˜ â€˜í•©ë‹ˆë‹¤ì²´(~ìŠµë‹ˆë‹¤/~ì…ë‹ˆë‹¤)â€™ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë°”ê¿”ì¤˜.",
    }
    instruction = style_map.get(level, style_map["hamnida"])

    user_prompt = (
        f"{text}\n\n"
        f"{instruction}\n"
        f"ì¶œë ¥ì€ ë³€í™˜ëœ ë³¸ë¬¸ë§Œ, ì„¤ëª…/ë”°ì˜´í‘œ/ë¨¸ë¦¬ë§ ì—†ì´ ê·¸ëŒ€ë¡œ ë‚´ë³´ë‚´."
    )

    co = cohere.ClientV2(COHERE_API_KEY)
    response = co.chat(
        model="command-a-03-2025",
        messages=[{"role": "user", "content": user_prompt}]
    )
    out = response.message.content[0].text
    return {"result": out, "level": level}

@app.post("/cohereInformal")
async def cohere_informal(payload: InformalInput):
    co = cohere.ClientV2(COHERE_API_KEY)

    # 'hada' | 'haetda' | 'hae' | ''
    ending = (payload.ending or "").strip().lower()

    ending_rules = {
        "hada": (
            "ëª¨ë“  ë¬¸ì¥ì„ '~ë‹¤'ë¡œ ëë‚˜ëŠ” í‰ì„œí˜•(â€¦í•œë‹¤/â€¦ì´ë‹¤)ìœ¼ë¡œ ì¨ì¤˜. "
            "êµ¬ì–´ì²´/í•´ìš”ì²´/ì¡´ì¹­ í‘œí˜„ì€ ì“°ì§€ ë§ ê²ƒ."
        ),
        "haetda": (
            "ëª¨ë“  ë¬¸ì¥ì„ ê³¼ê±° í‰ì„œí˜• '~í–ˆë‹¤/~ì˜€ë‹¤'ë¡œ ì¨ì¤˜. "
            "êµ¬ì–´ì²´/í•´ìš”ì²´/ì¡´ì¹­ í‘œí˜„ì€ ì“°ì§€ ë§ ê²ƒ."
        ),
        "hae": (
            "ëª¨ë“  ë¬¸ì¥ì„ '~í•´/~í–ˆì–´' ë°˜ë§ì²´ë¡œ ì¨ì¤˜."
        ),
    }
    # íŒŒë¼ë¯¸í„°ê°€ ì—†ìœ¼ë©´ ê¸°ì¡´ ë™ì‘(ë°˜ë§ '~í•´/~í–ˆì–´')ì„ ê·¸ëŒ€ë¡œ ìœ ì§€
    instruction = ending_rules.get(ending) or ending_rules["hae"]

    user_prompt = f"""{payload.content}

{instruction}
ì¶”ê°€ ê·œì¹™:
- ê²°ê³¼ëŠ” í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜(ì„¤ëª…/ë¨¸ë¦¬ë§/ë”°ì˜´í‘œ ê¸ˆì§€).
"""

    response = co.chat(
        model="command-a-03-2025",
        messages=[{"role": "user", "content": user_prompt}]
    )
    full_text = response.message.content[0].text
    return {"result": full_text}


@app.post("/translate")
async def translate_text(request: Request):
    body = await request.json()
    text = body.get("text")
    source = body.get("source", "None")
    target = body.get("target", "en")

    if not text:
        return {"error": "No text provided"}

    if translate_client is None:
        return {"error": "Translate client not initialized. Check GOOGLE_CREDENTIALS_JSON."}

    try:
        if source and source != "auto":
            result = translate_client.translate(
                text, source_language=source, target_language=target
            )
        else:
            result = translate_client.translate(text, target_language=target)

        translated_clean = html.unescape(result["translatedText"])
        return {"result": translated_clean}
    except Exception as e:
        return {"error": f"Google ë²ˆì—­ API í˜¸ì¶œ ì˜¤ë¥˜: {str(e)}"}

def extract_pdf_text(pdf_path: str) -> str:
    """
    PyPDF2ë¡œ PDFì˜ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³ , ì˜¨ì  ì• ê³µë°± ì œê±° ë“± ê°„ë‹¨ í›„ì²˜ë¦¬.
    """
    try:
        reader = PdfReader(pdf_path)
        extracted_text = ""
        for page in reader.pages:
            extracted_text += page.extract_text() or ""
        # ì˜¨ì  ì•ì˜ ë„ì–´ì“°ê¸° ì œê±°
        cleaned_text = re.sub(r" (?=\.)", "", extracted_text)
        return cleaned_text.strip()
    except Exception as e:
        raise RuntimeError(f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")


def libreoffice_to_pdf(input_path: str) -> str:
    """
    LibreOffice(headless)ë¡œ ê±°ì˜ ëª¨ë“  ì˜¤í”¼ìŠ¤/HWP í¬ë§·ì„ PDFë¡œ ë³€í™˜.
    ì˜ˆ: soffice --headless --convert-to pdf --outdir /tmp input.hwp
    """
    outdir = tempfile.gettempdir()

    cmd = ["soffice", "--headless", "--convert-to",
           "pdf", "--outdir", outdir, input_path]
    try:
        subprocess.run(cmd, check=True, stdout=subprocess.PIPE,
                       stderr=subprocess.PIPE)
        stem = pathlib.Path(input_path).stem
        out_pdf = os.path.join(outdir, f"{stem}.pdf")
        if not os.path.exists(out_pdf):
            raise RuntimeError("LibreOffice ë³€í™˜ ê²°ê³¼ PDFë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return out_pdf
    except subprocess.CalledProcessError as e:
        raise RuntimeError(
            f"LibreOffice ë³€í™˜ ì‹¤íŒ¨: {e.stderr.decode('utf-8', errors='ignore')}")

def extract_hwpx_text(local_path: str) -> str:
    """
    HWPXëŠ” OOXML ìœ ì‚¬ êµ¬ì¡°ì˜ 'ì••ì¶•(zip)+XML' í¬ë§·.
    Contents/*.xml ì—ì„œ ëª¨ë“  í…ìŠ¤íŠ¸ ë…¸ë“œ({*}t)ë¥¼ ê¸ì–´ì™€ ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ í•©ì¹©ë‹ˆë‹¤.
    """
    texts = []
    with zipfile.ZipFile(local_path, "r") as zf:

        xml_names = [n for n in zf.namelist()
                     if n.lower().startswith("contents/") and n.lower().endswith(".xml")]
        if not xml_names:

            xml_names = [n for n in zf.namelist(
            ) if n.lower().endswith(".xml")]

        for name in sorted(xml_names):
            with zf.open(name) as fp:
                data = fp.read()
            try:
                root = ET.fromstring(data)
            except ET.ParseError:
                continue

            for node in root.findall(".//{*}t"):
                if node.text and node.text.strip():
                    texts.append(node.text)

    text = "\n".join(texts)
    text = re.sub(r"[ \t]+\n", "\n", text)         #
    text = re.sub(r"\s{2,}", " ", text)            #
    text = re.sub(r"\s+(?=[\.\,\!\?\:\;])", "", text)
    return text.strip()

def extract_text_by_ext(local_path: str, filename: str) -> str:
    """
    íŒŒì¼ í™•ì¥ì/í¬ë§·ì— ë”°ë¼ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œ.
    - ì§ì ‘ ì¶”ì¶œ ê°€ëŠ¥í•œ í¬ë§·: pdf, docx, pptx, xlsx, txt
    - ê·¸ ì™¸(ppt, xls, hwp, hwpx, doc, rtf ë“±)ëŠ” LibreOfficeë¡œ pdf ë³€í™˜ í›„ PDF ì¶”ì¶œ ì¬ì‚¬ìš©
    """
    ext = pathlib.Path(filename).suffix.lower().lstrip(".")
    text = ""

    if ext == "pdf":
        text = extract_pdf_text(local_path)

    elif ext == "docx":
        # mammoth: docx -> plain text
        try:
            import mammoth
            with open(local_path, "rb") as f:
                result = mammoth.extract_raw_text(f)
            text = (result.value or "").strip()
        except Exception as e:
            raise RuntimeError(f"DOCX ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    elif ext == "pptx":
        # python-pptx: ëª¨ë“  ìŠ¬ë¼ì´ë“œì—ì„œ shape.text ëª¨ìœ¼ê¸°
        try:
            from pptx import Presentation
            prs = Presentation(local_path)
            chunks = []
            for slide in prs.slides:
                for shp in slide.shapes:
                    if hasattr(shp, "text") and shp.text:
                        chunks.append(shp.text)
                # ë…¸íŠ¸ ì˜ì—­ê¹Œì§€ í•„ìš”í•˜ë©´ ì•„ë˜ í™œì„±í™”
                if getattr(slide, "notes_slide", None) and slide.notes_slide.notes_text_frame:
                    chunks.append(slide.notes_slide.notes_text_frame.text)
            text = "\n".join(chunks).strip()
        except Exception as e:
            raise RuntimeError(f"PPTX ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    elif ext == "xlsx":
        # openpyxl: ì…€ í…ìŠ¤íŠ¸ë¥¼ ì‹œíŠ¸ë³„ë¡œ ëª¨ìœ¼ê¸°
        try:
            import openpyxl
            wb = openpyxl.load_workbook(
                local_path, data_only=True, read_only=True)
            rows = []
            for ws in wb.worksheets:
                rows.append(f"### ì‹œíŠ¸: {ws.title}")
                for row in ws.iter_rows(values_only=True):
                    cells = [str(c) if c is not None else "" for c in row]
                    # ë„ˆë¬´ ê¸´ ì—‘ì…€ì´ë©´ ì—¬ê¸°ì„œ ì¤„ìˆ˜/ì—´ìˆ˜ ì œí•œ ê°€ëŠ¥
                    rows.append("\t".join(cells))
            text = "\n".join(rows).strip()
        except Exception as e:
            raise RuntimeError(f"XLSX ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    elif ext == "txt":
        # ë‹¨ìˆœ í…ìŠ¤íŠ¸
        try:
            with open(local_path, "rb") as f:
                raw = f.read()
            text = raw.decode("utf-8", errors="ignore").strip()
        except Exception as e:
            raise RuntimeError(f"TXT ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    elif ext == "hwpx":
        # âœ… LibreOffice ì—†ì´ ë°”ë¡œ íŒŒì‹±
        text = extract_hwpx_text(local_path)

    elif ext in ("ppt", "xls", "hwp", "doc", "rtf"):
        # ì´ë“¤ì€ ê³„ì† LibreOffice ë³€í™˜ì„ ì‚¬ìš©
        pdf_path = libreoffice_to_pdf(local_path)
        text = extract_pdf_text(pdf_path)

    else:

        try:
            pdf_path = libreoffice_to_pdf(local_path)
            text = extract_pdf_text(pdf_path)
        except Exception as e:
            raise RuntimeError(f"LibreOffice ë³€í™˜/ì¶”ì¶œ ì‹¤íŒ¨: {e}")

    return text

@app.post("/fileScan")
async def file_scan(file: UploadFile = File(...)):
    try:
        binary = await file.read()
        filename = file.filename or "upload"
        ext = os.path.splitext(filename)[1].lower()

        if ext == ".pdf":
            # PDFëŠ” í˜ì´ì§€/ì¢Œí‘œ ê¸°ë°˜(ê°€ëŠ¥í•˜ë©´ extract_pdf_in_reading_order ì‚¬ìš©)
            merged = extract_pdf_in_reading_order_bytes(binary)  # ë˜ëŠ” ê¸°ì¡´ extract_pdf_text
        elif ext in (".docx", ".pptx", ".xlsx", ".hwpx", ".hwp"):
            # âœ… LibreOffice ë³€í™˜ ì—†ì´ í¬ë§·ë³„ íŒŒì„œ + ì´ë¯¸ì§€OCR
            merged = extract_office_like_bytes(binary, filename)  # ì•„ë˜ í—¬í¼ë“¤ë¡œ êµ¬í˜„
        else:
            # ê¸°íƒ€: í…ìŠ¤íŠ¸/ì´ë¯¸ì§€ íŒë³„í•´ì„œ ì²˜ë¦¬
            merged = try_generic_extract(binary, filename)

        if not merged:
            merged = ""

        # ë„ˆë¬´ ê¸¸ë©´ ì»·(ìˆë‹¤ë©´ ìœ ì§€)
        MAX = 100_000
        if len(merged) > MAX:
            merged = merged[:MAX] + "\nâ€¦(ìƒëµ)"

        return {"filename": filename, "text": merged}
    except Exception as e:
        print("âš ï¸ [fileScan fatal]", e)
        return {"filename": getattr(file, "filename", ""), "text": "", "error": str(e)}


@app.post("/pdfScan")
async def upload_pdf(pdf: UploadFile = File(...)):
    with tempfile.NamedTemporaryFile(delete=False, suffix=".pdf") as temp_pdf:
        contents = await pdf.read()
        temp_pdf.write(contents)
        temp_pdf_path = temp_pdf.name

    try:
        cleaned_text = extract_pdf_text(temp_pdf_path)
        return {"filename": pdf.filename, "text": cleaned_text}
    except Exception as e:
        return {"error": f"PDF ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"}
    finally:
        try:
            os.remove(temp_pdf_path)
        except:
            pass

# ë‹¨ë… ìëª¨ ì œê±°(í›„ì²˜ë¦¬)
def clean_ocr_text(text: str) -> str:
    """
    ë‹¨ë… ìëª¨(ã…, ã„± ë“±)ë‚˜ ì¡ìŒì„ ì œê±°í•¨.
    """
    cleaned_lines = []
    for line in text.split('\n'):
        stripped = line.strip()
        # ë‹¨ë… ìëª¨ë‚˜ 1~2ê¸€ì ì¡ìŒ ì œê±°
        if re.fullmatch(r'[ã„±-ã…ã…-ã…£\s]*', stripped):
            continue
        if len(stripped) <= 2 and re.search(r'[ã„±-ã…ã…-ã…£]', stripped):
            continue
        cleaned_lines.append(line)
    return '\n'.join(cleaned_lines)

@app.post("/visionOCR")
async def vision_ocr(image: UploadFile = File(...)):
    try:
        if vision_client is None:
            return {"result": "Vision client not initialized. Check GOOGLE_APPLICATION_CREDENTIALS_JSON."}

        contents = await image.read()
        image_content = vision.Image(content=contents)
        response = vision_client.text_detection(image=image_content)

        texts = response.text_annotations
        if not texts:
            return {"result": "í…ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}

        raw_text = texts[0].description
        cleaned_text = clean_ocr_text(raw_text)
        return {"result": cleaned_text}
    except Exception as e:
        print("âŒ ì„œë²„ ì—ëŸ¬:", e)
        return {"result": f"ì„œë²„ ì—ëŸ¬: {e}"}

@app.post("/speech")
async def upload_audio(audio: UploadFile = File(...)):
    start_time = time.time()

    # ì—…ë¡œë“œëœ ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°
    audio_bytes = await audio.read()
    audio_segment = AudioSegment.from_file(BytesIO(audio_bytes), format="wav")

    # (ì„ íƒ) ì˜¤ë””ì˜¤ ì „ì²˜ë¦¬
    silence = AudioSegment.silent(duration=1000)
    audio_segment = silence + audio_segment
    audio_segment = audio_segment.set_frame_rate(
        16000).set_channels(1).set_sample_width(2)
    audio_segment = audio_segment.normalize()
    audio_segment += 6

    print("í˜„ì¬ í‰ê·  ë°ì‹œë²¨:", audio_segment.dBFS)

    # ì „ì²´ ì˜¤ë””ì˜¤ ê·¸ëŒ€ë¡œ ì‚¬ìš©
    recognizer = sr.Recognizer()
    with BytesIO() as wav_buffer:
        audio_segment.export(wav_buffer, format="wav")
        wav_buffer.seek(0)
        with sr.AudioFile(wav_buffer) as source:
            # (ì„ íƒ) ì¡ìŒ ë³´ì •
            recognizer.adjust_for_ambient_noise(source, duration=1)
            audio_data = recognizer.record(source)  # ì „ì²´ íŒŒì¼ í•œ ë²ˆì— ì½ìŒ

            try:
                result = recognizer.recognize_google(
                    audio_data, language="ko-KR", show_all=True)
                if "alternative" in result:
                    text = result["alternative"][0]["transcript"]
                else:
                    text = ""
            except sr.UnknownValueError:
                text = ""
                print("ì˜¤ë””ì˜¤ ì¸ì‹ ì‹¤íŒ¨")
            except sr.RequestError as e:
                text = ""
                print("Google Web Speech API ìš”ì²­ ì˜¤ë¥˜:", e)

    elapsed_time = time.time() - start_time

    if (text):
        print("\n" + text + "\n")
    print(f"ê±¸ë¦° ì‹œê°„: {elapsed_time:.3f}ì´ˆ")
    print()

    return {"text": text, "time": round(elapsed_time, 3)}

@app.post("/editorGrammar")
async def editorGrammar(content: TextInput):
    print(content.content)
    print()

    result = spell_checker.check(content.content)

    print(f"ì›ë¬¸        : {result.original}")
    print(f"ìˆ˜ì •ëœ ë¬¸ì¥ : {result.checked}")
    print(f"ì˜¤ë¥˜ ìˆ˜     : {result.errors}")
    print(f"ë‹¨ì–´ë³„ ìƒíƒœ : {list(result.words.keys())}")
    print(f"ê²€ì‚¬ ì‹œê°„   : {result.time:.4f}ì´ˆ")
    print("-" * 40)

    return {
        "original": result.original,
        "checked": result.checked,
        "errors": result.errors,
        # "words": list(result.words.keys()),
        "time": result.time,
    }
@app.post("/promptChange")
async def expand(request: Request):
    body = await request.json()

    content = body.get('content')
    prompt = body.get('prompt')
    print(content)
    print(prompt)
    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸€ì„ ìˆ˜ì •í•´ì£¼ëŠ” ì‘ë¬¸ ë³´ì¡° ë„êµ¬ì…ë‹ˆë‹¤."},
            {"role": "user", "content": f"{content}ìœ„ì˜ ê¸€ì„ ì•„ë˜ í”„ë¡¬í”„íŠ¸ì— ë§ê²Œ ìˆ˜ì •í•´ì¤˜.\n\n{prompt}"}
        ]
    )
    message = response.choices[0].message.content
    return {"result": message}

@app.post("/promptAdd")
async def expand(request: Request):
    body = await request.json()

    before = body.get('before')
    after = body.get('after')
    prompt = body.get('prompt')

    response = client.chat.completions.create(
        model="gpt-4",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ê¸€ì„ ìˆ˜ì •í•´ì£¼ëŠ” ì‘ë¬¸ ë³´ì¡° ë„êµ¬ì…ë‹ˆë‹¤."},
            {"role": "user", "content": f"í˜„ì¬ ì»¤ì„œ ì „ì˜ ê¸€: {before}\n\ní˜„ì¬ ì»¤ì„œ ì´í›„ì˜ ê¸€: {after}\n\ní˜„ì¬ ì»¤ì„œë¥¼ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬í•œ ê¸€ë“¤ì„ ì•„ë˜ í”„ë¡¬í”„íŠ¸ì— ë§ê²Œ ìˆ˜ì •í•´ì¤˜. ê²°ê³¼ëŠ” ì¶”ê°€í•  ê¸€ë§Œ ì•Œë ¤ì¤˜.\n\n{prompt}"}
        ]
    )
    message = response.choices[0].message.content

    # ê¸€ ì• ë’¤ ë”°ì˜´í‘œ ì œê±°
    message = message[1:-1] if len(
        message) >= 2 and message[0] == message[-1] and message[0] in ('"', "'") else message
    print(message)
    return {"result": message}



